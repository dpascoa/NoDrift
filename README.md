# Web Crawler Pro ğŸš€

A modern, interactive web crawler with a beautiful real-time interface. Transform your command-line crawler into a sleek web application with live progress tracking, animated statistics, and responsive design.

## âœ¨ Features

- **ğŸ¨ Modern UI**: Beautiful gradient design with glassmorphism effects
- **âš¡ Real-time Updates**: Live progress tracking and statistics
- **ğŸ“Š Interactive Dashboard**: Visual stats showing pages crawled, elapsed time, and URLs found
- **ğŸ“± Responsive Design**: Works perfectly on desktop and mobile devices  
- **ğŸ”„ Async Crawling**: Fast, concurrent web crawling with aiohttp
- **ğŸ¯ Smart Filtering**: Only crawls same-domain links with URL normalization
- **ğŸŒ Flexible URL Input**: Automatically completes URLs - works with `example.com`, `www.example.com`, or `https://example.com`
- **â¹ï¸ Stop/Start Control**: Full control over crawling sessions
- **ğŸ“ Detailed Logging**: See each page being crawled in real-time
- **âœ… URL Validation**: Intelligent URL validation and error handling

## ğŸ—ï¸ Project Structure

```
web-crawler-pro/
â”œâ”€â”€ app.py                    # Flask web server
â”œâ”€â”€ run_web.py               # Startup script
â”œâ”€â”€ main.py                  # Original CLI version
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ crawler/                # Crawler module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawler.py          # Main crawler class
â”‚   â””â”€â”€ utils.py            # Utility functions
â”œâ”€â”€ test/                   # Test files
â”‚   â”œâ”€â”€ test_crawler_async.py
â”‚   â”œâ”€â”€ test_crawler_parse_links.py
â”‚   â”œâ”€â”€ test_extra_coverage.py
â”‚   â””â”€â”€ test_utils.py
â””â”€â”€ templates/              # HTML templates
    â””â”€â”€ index.html          # Web interface
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the Web Interface

**Option A: Using the startup script (Recommended)**
```bash
python run_web.py
```

**Option B: Direct Flask run**
```bash
python app.py
```

### 3. Open Your Browser

The application will automatically open at `http://localhost:5000`

### 4. Start Crawling

1. Enter a website URL in any of these formats:
   - `sapo.pt` (will become `https://www.sapo.pt`)
   - `www.sapo.pt` (will become `https://www.sapo.pt`) 
   - `https://www.sapo.pt` (used as-is)
2. Click "Start Crawling"
3. Watch the real-time progress!

## ğŸŒ URL Format Support

The crawler intelligently handles various URL formats:

| Input Format | Automatically Becomes | Notes |
|---|---|---|
| `sapo.pt` | `https://www.sapo.pt` | Adds protocol and www |
| `www.sapo.pt` | `https://www.sapo.pt` | Adds protocol only |
| `https://sapo.pt` | `https://sapo.pt` | Used as provided |
| `http://www.sapo.pt` | `http://www.sapo.pt` | Respects HTTP if specified |

### Invalid URL Examples
- Empty strings
- Plain text without domains  
- Malformed URLs

The system will show clear error messages for invalid inputs.

## ğŸ”§